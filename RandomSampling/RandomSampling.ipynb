{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "source": [
    "# Tugas Akhir Machine Learning\n",
    "## Nilai A Barokah \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140707, 79)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "attribute_name = ['ncd', 'ai', 'as_na', 'bl', 'nac', 'as_nac', 'cs', 'at', 'na', 'adl', 'nad']\n",
    "days = [0, 1, 2, 3, 4, 5, 6]\n",
    "name = []\n",
    "\n",
    "#penamaan dari data\n",
    "name.append('index')\n",
    "\n",
    "for i in range(len(attribute_name)):\n",
    "    for j in range(len(days)):\n",
    "        name.append(attribute_name[i]+\"_\"+str(days[j]))\n",
    "\n",
    "name.append('label')\n",
    "\n",
    "#pembacaan data dari file csv\n",
    "#data berasal dari http://ama.liglab.fr/resourcestools/datasets/buzz-prediction-in-social-media/\n",
    "twitter_data = pd.read_csv('data_modif.csv', skiprows=[0], names = name)\n",
    "\n",
    "#mengetahui dimensi data\n",
    "print(twitter_data.shape)\n",
    "\n",
    "#5 baris data pertama\n",
    "#print(twitter_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               index          ncd_0          ncd_1          ncd_2  \\\n",
      "count  140707.000000  140707.000000  140707.000000  140707.000000   \n",
      "mean    70354.000000     172.279823     155.150625     165.464476   \n",
      "std     40618.756501     509.872276     471.573236     495.360236   \n",
      "min         1.000000       0.000000       0.000000       0.000000   \n",
      "25%     35177.500000       3.000000       2.000000       3.000000   \n",
      "50%     70354.000000      22.000000      19.000000      20.000000   \n",
      "75%    105530.500000     125.000000     112.000000     119.000000   \n",
      "max    140707.000000   24210.000000   22899.000000   20495.000000   \n",
      "\n",
      "               ncd_3          ncd_4          ncd_5          ncd_6  \\\n",
      "count  140707.000000  140707.000000  140707.000000  140707.000000   \n",
      "mean      176.820549     186.937700     216.209208     243.866510   \n",
      "std       528.351277     560.331281     632.188378     707.402192   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         3.000000       3.000000       4.000000       5.000000   \n",
      "50%        22.000000      23.000000      28.000000      33.000000   \n",
      "75%       126.000000     133.000000     161.000000     186.000000   \n",
      "max     27007.000000   30957.000000   28603.000000   37505.000000   \n",
      "\n",
      "                ai_0           ai_1      ...                adl_5  \\\n",
      "count  140707.000000  140707.000000      ...        140707.000000   \n",
      "mean       87.050154      78.639236      ...             1.113444   \n",
      "std       234.731748     218.448179      ...             1.374287   \n",
      "min         0.000000       0.000000      ...             0.000000   \n",
      "25%         2.000000       2.000000      ...             1.000000   \n",
      "50%        13.000000      11.000000      ...             1.000000   \n",
      "75%        70.000000      64.000000      ...             1.100000   \n",
      "max     15105.000000   15730.000000      ...           185.666672   \n",
      "\n",
      "               adl_6          nad_0          nad_1          nad_2  \\\n",
      "count  140707.000000  140707.000000  140707.000000  140707.000000   \n",
      "mean        1.196131     172.838807     155.630878     165.938674   \n",
      "std         1.826150     510.937549     472.462733     496.233557   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         1.000000       3.000000       2.000000       3.000000   \n",
      "50%         1.000000      22.000000      19.000000      21.000000   \n",
      "75%         1.119048     126.000000     113.000000     119.000000   \n",
      "max       295.000000   24301.000000   22980.000000   20495.000000   \n",
      "\n",
      "               nad_3          nad_4          nad_5          nad_6  \\\n",
      "count  140707.000000  140707.000000  140707.000000  140707.000000   \n",
      "mean      177.314810     187.463794     216.776294     244.479194   \n",
      "std       529.286514     561.309487     633.203935     708.436795   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         3.000000       3.000000       4.000000       6.000000   \n",
      "50%        22.000000      23.000000      28.000000      33.000000   \n",
      "75%       127.000000     134.000000     162.000000     187.000000   \n",
      "max     27071.000000   31028.000000   28697.000000   37505.000000   \n",
      "\n",
      "               label  \n",
      "count  140707.000000  \n",
      "mean        0.197396  \n",
      "std         0.398035  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "#deskripsi statistik dimasukkan ke dalam file csv\n",
    "twitter_data.describe().transpose().to_csv('deskripsi_statistik.csv', sep=',')\n",
    "\n",
    "#deskripsi statistik\n",
    "print(twitter_data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson correlation dari masing-masing attribute\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[112932, 27775]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_x = [0,1]\n",
    "\n",
    "label_0 = 0\n",
    "label_1 = 0\n",
    "\n",
    "for i in range(len(twitter_data.label)):\n",
    "    if twitter_data.label[i] == 0:\n",
    "        label_0 += 1\n",
    "    elif twitter_data.label[i] == 1:\n",
    "        label_1 += 1\n",
    "\n",
    "label_y = [label_0, label_1]\n",
    "        \n",
    "print(label_x)\n",
    "print(label_y)\n",
    "        \n",
    "plt.bar(label_x, label_y, label=\"Label\", color='b')\n",
    "plt.xlabel('Target 0          -          Target 1')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.title('Histogram Prediction Target')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Attribute Plot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from statistics import mean\n",
    "\n",
    "average = [0,0,0,0,0,0,0]\n",
    "hari = [1,2,3,4,5,6,7]\n",
    "\n",
    "ncd = [twitter_data.ncd_0, twitter_data.ncd_1, twitter_data.ncd_2, twitter_data.ncd_3, twitter_data.ncd_4, twitter_data.ncd_5, twitter_data.ncd_6]\n",
    "ai = [twitter_data.ai_0, twitter_data.ai_1, twitter_data.ai_2, twitter_data.ai_3, twitter_data.ai_4, twitter_data.ai_5, twitter_data.ai_6]\n",
    "as_na = [twitter_data.as_na_0, twitter_data.as_na_1, twitter_data.as_na_2, twitter_data.as_na_3, twitter_data.as_na_4, twitter_data.as_na_5, twitter_data.as_na_6]\n",
    "bl = [twitter_data.bl_0, twitter_data.bl_1, twitter_data.bl_2, twitter_data.bl_3, twitter_data.bl_4, twitter_data.bl_5, twitter_data.bl_6]\n",
    "adl = [twitter_data.adl_0, twitter_data.adl_1, twitter_data.adl_2, twitter_data.adl_3, twitter_data.adl_4, twitter_data.adl_5, twitter_data.adl_6]\n",
    "\n",
    "for i in range(7): \n",
    "    average[i] = statistics.mean(ncd[i])\n",
    "    \n",
    "plt.plot(hari, average)\n",
    "plt.title('Number of Created Discussions (NCD)')\n",
    "plt.show()\n",
    "\n",
    "average = [0,0,0,0,0,0,0]\n",
    "    \n",
    "for i in range(7): \n",
    "    average[i] = statistics.mean(ai[i])\n",
    "    \n",
    "plt.plot(hari, average)\n",
    "plt.title('Author Increase (AI)')\n",
    "plt.show()\n",
    "\n",
    "average = [0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range(7): \n",
    "    average[i] = statistics.mean(as_na[i])\n",
    "\n",
    "plt.plot(hari, average)\n",
    "plt.title('Attention Level (AS_NA)')\n",
    "plt.show()\n",
    "\n",
    "average = [0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range(7): \n",
    "    average[i] = statistics.mean(bl[i])\n",
    "    \n",
    "plt.plot(hari, average)\n",
    "plt.title('Burstiness Level (BL)')\n",
    "plt.show()\n",
    "\n",
    "average = [0,0,0,0,0,0,0]\n",
    "    \n",
    "for i in range(7): \n",
    "    average[i] = statistics.mean(adl[i])\n",
    "    \n",
    "plt.plot(hari, average)\n",
    "plt.title('Average Discussions Length (ADL)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sampling of Data with Label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27775, 79)\n",
      "(27775, 79)\n",
      "(55550, 79)\n",
      "         index  ncd_0  ncd_1  ncd_2  ncd_3  ncd_4  ncd_5  ncd_6  ai_0  ai_1  \\\n",
      "8318      8319      5     10      3      4      3      4      7     4     8   \n",
      "99229    99230     22     29     47     37     49     24     31    13     8   \n",
      "114        115      0      2      0      0      0      1      1     0     2   \n",
      "4427      4428     34     25     30     24     23     49     41    28    19   \n",
      "116466  116467      7      8     11     14      8      9     11     4     3   \n",
      "\n",
      "        ...       adl_5     adl_6  nad_0  nad_1  nad_2  nad_3  nad_4  nad_5  \\\n",
      "8318    ...    1.500000  3.500000      5     10      4      5      3      4   \n",
      "99229   ...    1.000000  1.032258     22     29     47     37     49     24   \n",
      "114     ...    1.000000  1.000000      0      2      0      0      0      1   \n",
      "4427    ...    1.000000  1.024390     34     26     30     24     23     49   \n",
      "116466  ...    1.111111  1.272727      7      8     11     14      8      9   \n",
      "\n",
      "        nad_6  label  \n",
      "8318        8      0  \n",
      "99229      31      0  \n",
      "114         1      0  \n",
      "4427       41      0  \n",
      "116466     11      0  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "twitter_data_label0 = twitter_data[twitter_data.label == 0]\n",
    "#print(twitter_data_label0.shape)\n",
    "#print(twitter_data_label0.head(5))\n",
    "\n",
    "sample_twitter_data_label0 = twitter_data_label0.sample(n=27775)\n",
    "print(sample_twitter_data_label0.shape)\n",
    "#print(sample_twitter_data_label0.head(5))\n",
    "\n",
    "twitter_data_label1 = twitter_data[twitter_data.label == 1]\n",
    "print(twitter_data_label1.shape)\n",
    "#print(twitter_data_label1.head(5))\n",
    "\n",
    "twitter_data = pd.concat([sample_twitter_data_label0, twitter_data_label1])\n",
    "print(twitter_data.shape)\n",
    "print(twitter_data.head())\n",
    "\n",
    "twitter_data.to_csv('RandomSampling.csv', float_format = '%.6f', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a Lazy DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b Eager DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
